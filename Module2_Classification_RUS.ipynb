{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in d:\\softwares\\anaconda\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in d:\\softwares\\anaconda\\lib\\site-packages (from imblearn) (0.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in d:\\softwares\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\softwares\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\softwares\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\softwares\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\softwares\\anaconda\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data\\\\Data.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quarter            0\n",
       "Month              0\n",
       "DayofMonth         0\n",
       "FlightDate         0\n",
       "OriginAirportID    0\n",
       "DestAirportID      0\n",
       "Dest               0\n",
       "CRSDepTime         0\n",
       "DepTime            0\n",
       "DepDelayMinutes    0\n",
       "DepDel15           0\n",
       "CRSArrTime         0\n",
       "ArrTime            0\n",
       "ArrDelayMinutes    0\n",
       "ArrDel15           0\n",
       "Unnamed: 0         0\n",
       "windspeedKmph      0\n",
       "visibility         0\n",
       "weatherCode        0\n",
       "precipMM           0\n",
       "WindGustKmph       0\n",
       "pressure           0\n",
       "cloudcover         0\n",
       "winddirDegree      0\n",
       "humidity           0\n",
       "DewPointF          0\n",
       "tempF              0\n",
       "time               0\n",
       "WindChillF         0\n",
       "date               0\n",
       "place              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['ArrDel15']\n",
    "X = df.drop(['ArrDel15','FlightDate','date','place','ArrDelayMinutes','ArrTime','Unnamed: 0'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    310080\n",
       "0.0    310080\n",
       "Name: ArrDel15, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "X_train, y_train = rus.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logy_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.8958157198847169\n",
      "Confusion Matrix\n",
      " [[270983  21316]\n",
      " [ 17255  60665]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.94      0.93      0.93    292299\n",
      "     Class 1       0.74      0.78      0.76     77920\n",
      "\n",
      "    accuracy                           0.90    370219\n",
      "   macro avg       0.84      0.85      0.85    370219\n",
      "weighted avg       0.90      0.90      0.90    370219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Performance Metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test, logy_pred))\n",
    "cm = metrics.confusion_matrix(y_test, logy_pred)\n",
    "print('Confusion Matrix\\n',cm)\n",
    "target_names=[\"Class 0\",\"Class 1\"]\n",
    "print('Classification Report\\n',classification_report(y_test, logy_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dty_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.7917935060059046\n",
      "Confusion Matrix\n",
      " [[230521  61778]\n",
      " [ 15304  62616]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.94      0.79      0.86    292299\n",
      "     Class 1       0.50      0.80      0.62     77920\n",
      "\n",
      "    accuracy                           0.79    370219\n",
      "   macro avg       0.72      0.80      0.74    370219\n",
      "weighted avg       0.85      0.79      0.81    370219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Performance Metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test, dty_pred))\n",
    "cm = metrics.confusion_matrix(y_test, dty_pred)\n",
    "print('Confusion Matrix\\n',cm)\n",
    "target_names=[\"Class 0\",\"Class 1\"]\n",
    "print('Classification Report\\n',classification_report(y_test, dty_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcy_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance Metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test, etcy_pred))\n",
    "cm = metrics.confusion_matrix(y_test, etcy_pred)\n",
    "print('Confusion Matrix\\n',cm)\n",
    "target_names=[\"Class 0\",\"Class 1\"]\n",
    "print('Classification Report\\n',classification_report(y_test, etcy_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(n_jobs=-1,random_state = None)\n",
    "etc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "etcy_pred = etc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.889062960031765\n",
      "Confusion Matrix\n",
      " [[265771  26528]\n",
      " [ 14543  63377]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.95      0.91      0.93    292299\n",
      "     Class 1       0.70      0.81      0.76     77920\n",
      "\n",
      "    accuracy                           0.89    370219\n",
      "   macro avg       0.83      0.86      0.84    370219\n",
      "weighted avg       0.90      0.89      0.89    370219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Performance Metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test, etcy_pred))\n",
    "cm = metrics.confusion_matrix(y_test, etcy_pred)\n",
    "print('Confusion Matrix\\n',cm)\n",
    "target_names=[\"Class 0\",\"Class 1\"]\n",
    "print('Classification Report\\n',classification_report(y_test, etcy_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgby_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.8957049746231285\n",
      "Confusion Matrix\n",
      " [[269206  23093]\n",
      " [ 15519  62401]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.95      0.92      0.93    292299\n",
      "     Class 1       0.73      0.80      0.76     77920\n",
      "\n",
      "    accuracy                           0.90    370219\n",
      "   macro avg       0.84      0.86      0.85    370219\n",
      "weighted avg       0.90      0.90      0.90    370219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Performance Metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test, xgby_pred))\n",
    "cm = metrics.confusion_matrix(y_test, xgby_pred)\n",
    "print('Confusion Matrix\\n',cm)\n",
    "target_names=[\"Class 0\",\"Class 1\"]\n",
    "print('Classification Report\\n',classification_report(y_test, xgby_pred,target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
